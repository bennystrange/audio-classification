{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d0e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "from scipy.fft import fft, fftfreq\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# in theory, this should automagically detect whether or not you're in colab and set the directory accordingly\n",
    "# if in colab, put link to shared 378final folder in My Drive\n",
    "# if local, make a dataset folder containing the .wav folders in the same directory as the .py file\n",
    "# we won't track dataset folder on Git because it's 2GB Lol.\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    dataset_directory = \"/content/drive/My Drive/378final/dataset\"\n",
    "except:\n",
    "    dataset_directory = \"./dataset\"\n",
    "\n",
    "# Hardcoded labels\n",
    "labels = [\"Angry\", \"Disgusted\", \"Fearful\", \"Happy\", \"Neutral\", \"Sad\", \"Suprised\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d6f78",
   "metadata": {},
   "source": [
    "Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e44596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe basic data exploration above provides intuition for extracting features or processing raw data to be in a different format that might allow for better ML models (think linear separability).\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Data Exploration (FFT & PSD)\"\"\"\n",
    "\n",
    "# we would like to get a sense of the signal's properties so see what are some good features to extract\n",
    "#j = 1\n",
    "#for emotion in labels:\n",
    "emotion = \"Angry\"\n",
    "for j in range(1, 4):\n",
    "    file_name = f\"{dataset_directory}/{emotion}/{emotion}{j}.wav\"\n",
    "    audio, sampling_rate = librosa.load(file_name, sr=8000)  # load full audio signal\n",
    "\n",
    "    fig,axs = plt.subplots(3,2)\n",
    "    \n",
    "    # raw audio waveform\n",
    "    #plt.figure(figsize=(8, 6))\n",
    "    #librosa.display.waveshow(audio, sr=sampling_rate, color = \"green\")\n",
    "    axs[0,0].plot([i/sampling_rate for i in range(audio.shape[0])], audio, color = \"green\")\n",
    "    axs[0,0].set_title(\"Waveform\")\n",
    "    axs[0,0].set_xlabel(\"Time (s)\")\n",
    "    axs[0,0].set_ylabel(\"Amplitude\")\n",
    "    axs[0,0].grid()\n",
    "\n",
    "    # fft\n",
    "    N = len(audio)\n",
    "    yf = fft(audio)\n",
    "    xf = fftfreq(N, 1 / sampling_rate)[:N // 2]\n",
    "    #plt.figure(figsize=(8, 6))\n",
    "    axs[0,1].plot(xf, 2.0 / N * np.abs(yf[0:N // 2]), color = \"blue\")\n",
    "    axs[0,1].set_title(\"FFT\")\n",
    "    axs[0,1].set_xlabel(\"Frequency (Hz)\")\n",
    "    axs[0,1].set_ylabel(\"Amplitude\")\n",
    "    axs[0,1].grid()\n",
    "    axs[0,1].set_xscale(\"log\")\n",
    "    #plt.show()\n",
    "\n",
    "    # psd\n",
    "    f, Pxx = welch(audio, sampling_rate, nperseg=1024)\n",
    "    #plt.figure(figsize=(8, 6))\n",
    "    axs[1,0].set_title(\"PSD\")\n",
    "    axs[1,0].set_xlabel(\"Frequency (Hz)\")\n",
    "    axs[1,0].set_ylabel(\"Power Spectral Density\")\n",
    "    axs[1,0].grid()\n",
    "    axs[1,0].semilogy(f, Pxx, color = \"orange\")\n",
    "    axs[1,0].set_xscale(\"log\")\n",
    "    #plt.show()\n",
    "\n",
    "    # mfcc\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sampling_rate, n_mels=128) #can experiment with n_mels (try 22-128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mfccs = librosa.feature.mfcc(S=mel_spec_db, sr=sampling_rate, n_mfcc=12) #experiment with n_mfcc?? (8-20)\n",
    "\n",
    "    delta_mfccs  = librosa.feature.delta(mfccs)\n",
    "    delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "\n",
    "    #librosa.display.specshow(mfccs, sr=sampling_rate, x_axis='time')\n",
    "    #pcm = axs[1,1].pcolormesh(mfccs)\n",
    "    #fig.colorbar(pcm,ax=axs[1,1], shrink=0.6)\n",
    "    #plt.figure(figsize=(8, 6))\n",
    "    axs[1,1].imshow(mfccs, cmap=\"hot\", interpolation=\"nearest\", origin=\"lower\")\n",
    "    axs[1,1].set_title(\"MFCCs\")\n",
    "    axs[1,1].set_xlabel(\"Time\")\n",
    "    axs[1,1].set_ylabel(\"MFCC Coefficients\")\n",
    "\n",
    "    axs[2,0].imshow(delta_mfccs, cmap=\"hot\", interpolation=\"nearest\", origin=\"lower\")\n",
    "    axs[2,0].set_title(\"Derivative of MFCCs\")\n",
    "    axs[2,0].set_xlabel(\"Time\")\n",
    "    axs[2,0].set_ylabel(\"MFCC Coefficients\")\n",
    "\n",
    "    axs[2,1].imshow(delta2_mfccs, cmap=\"hot\", interpolation=\"nearest\", origin=\"lower\")\n",
    "    axs[2,1].set_title(\"Second Derivative of MFCCs\")\n",
    "    axs[2,1].set_xlabel(\"Time\")\n",
    "    axs[2,1].set_ylabel(\"MFCC Coefficients\")\n",
    "    \n",
    "    fig.suptitle(f\"Features of {emotion}{j}.wav\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The basic data exploration above provides intuition for extracting features or processing raw data to be in a different format that might allow for better ML models (think linear separability).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639a729",
   "metadata": {},
   "source": [
    "Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbc81121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature Extraction (per audio signal)\n",
    "\"\"\"\n",
    "def extract_features(file_path, standard_audio_size=3):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        # Apparently the sampling rate differs between files, so we fix it here\n",
    "        audio, sampling_rate = librosa.load(file_path, sr=8000)\n",
    "\n",
    "        # Pad/truncate to get standard length (so features are consistent length)\n",
    "        padded_audio = librosa.util.fix_length(audio, size=standard_audio_size*sampling_rate)\n",
    "\n",
    "        # Extract features\n",
    "        mel_spec = librosa.feature.melspectrogram(y=padded_audio, sr=sampling_rate, n_mels=128)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        mfccs = librosa.feature.mfcc(S=mel_spec_db, sr=sampling_rate, n_mfcc=12)\n",
    "        delta_mfccs  = librosa.feature.delta(mfccs)\n",
    "        delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "        #chroma = librosa.feature.chroma_stft(y=audio_timeseries, sr=sampling_rate)\n",
    "\n",
    "        all_features = np.vstack([mfccs, delta_mfccs, delta2_mfccs]).flatten(order='F')\n",
    "        #librosa_features_mean = np.mean(all_features, axis=1)\n",
    "        return all_features\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "#Note: This is just a small sample of all the features you can extract from audio signals. Look at what the librosa library has to offer!\n",
    "#Another Note: This is an example of feature extraction per data point (signal). You could also do something like PCA on all the raw\n",
    "#               train data (as in directly on the audio signals) or PCA on all data as the computed features per datapoint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183888af",
   "metadata": {},
   "source": [
    "Extracting Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19b4b443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Extracting Train Data---\n",
      "Extracting: Angry\n",
      "Extracting: Disgusted\n",
      "Extracting: Fearful\n",
      "Extracting: Happy\n",
      "Extracting: Neutral\n",
      "Extracting: Sad\n",
      "Extracting: Suprised\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Loading Features\"\"\"\n",
    "print(\"---Extracting Train Data---\")\n",
    "\n",
    "# Load dataset and extract features\n",
    "features = []\n",
    "labels_for_features = []\n",
    "\n",
    "for label in labels:\n",
    "    print(f\"Extracting: {label}\")\n",
    "    for num, file_name in enumerate(os.listdir(f\"{dataset_directory}/{label}\")):\n",
    "        if (num < 100): # comment this out this to use ALL files\n",
    "            file_path = f\"{dataset_directory}/{label}/{file_name}\"\n",
    "            extracted_features = extract_features(file_path)\n",
    "            if extracted_features is not None:\n",
    "                features.append(extracted_features)\n",
    "                labels_for_features.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7134dd",
   "metadata": {},
   "source": [
    "Training Model w/ Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be87cd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Training Model---\n",
      "Split #1\n",
      "Split #2\n",
      "Split #3\n",
      "Split #4\n",
      "Split #5\n",
      "Average Accuracy: 39.00%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Model + Trainer\"\"\"\n",
    "print(\"---Training Model---\")\n",
    "\n",
    "# Convert to numpy arrays and continue as before\n",
    "features = np.array(features)\n",
    "labels_for_features = np.array(labels_for_features)\n",
    "with open(f\"{dataset_directory}/train_features.npy\", \"wb\") as f:\n",
    "    np.save(f, features)\n",
    "with open(f\"{dataset_directory}/train_labels.npy\",\"wb\") as f:\n",
    "    np.save(f, labels_for_features)\n",
    "#converts labels to unique integers\n",
    "#this may be optional\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels_for_features)\n",
    "\n",
    "#print(\"encoded labels\", labels_encoded)\n",
    "\n",
    "# Initialize cross-validation (you can use this or simple train test split although this will make testing of your model more robust!)\n",
    "kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "accuracies = []\n",
    "\n",
    "\"\"\"\n",
    "Alternatively, you can also simply use sklearn's train_test_split function!! Cross validation is K different random combinations\n",
    "of this train and test data split in order to train the model more robustly and ultimately use all your available data for the kaggle competition.\n",
    "\"\"\"\n",
    "\n",
    "# SVM Model and preprocessing initialization\n",
    "svm_clf = SVC(kernel=\"rbf\", C=1, gamma=\"auto\")\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=0.95) # keep enough components to preserve 95% of the variance in the data\n",
    "\n",
    "# Perform cross-validation\n",
    "for i, (train_index, test_index) in enumerate(kf.split(features, labels_encoded)):\n",
    "    print(f\"Split #{i+1}\")\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels_encoded[train_index], labels_encoded[test_index]\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    # NOTE: PCA IS A MAJOR SLOWDOWN! THE BIGGER THE DATASET, THE LONGER IT TAKES!\n",
    "    # fitting the svm is genuinely faster than the pca\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "    svm_clf.fit(X_train_pca, y_train)\n",
    "    y_pred = svm_clf.predict(X_test_pca)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Average Accuracy: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a39b1",
   "metadata": {},
   "source": [
    "Extracting Test Data and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ddbc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Extracting Test Data---\n",
      "Extraction 0% complete\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n",
      "(1, 1692)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExtraction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(\u001b[32m100\u001b[39m*checkpoints.index(num)/\u001b[32m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m% complete\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m file_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/Test/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m the_thing = \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m the_thing \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     18\u001b[39m     test_features.append(the_thing.reshape(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mextract_features\u001b[39m\u001b[34m(file_path, standard_audio_size)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_features\u001b[39m(file_path, standard_audio_size=\u001b[32m3\u001b[39m):\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      6\u001b[39m         \u001b[38;5;66;03m# Load the audio file\u001b[39;00m\n\u001b[32m      7\u001b[39m         \u001b[38;5;66;03m# Apparently the sampling rate differs between files, so we fix it here\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m         audio, sampling_rate = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m         \u001b[38;5;66;03m# Pad/truncate to get standard length (so features are consistent length)\u001b[39;00m\n\u001b[32m     11\u001b[39m         padded_audio = librosa.util.fix_length(audio, size=standard_audio_size*sampling_rate)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\audio.py:193\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[39m\n\u001b[32m    190\u001b[39m     y = to_mono(y)\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     y = \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr_native\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mres_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    196\u001b[39m     sr = sr_native\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\audio.py:669\u001b[39m, in \u001b[36mresample\u001b[39m\u001b[34m(y, orig_sr, target_sr, res_type, fix, scale, axis, **kwargs)\u001b[39m\n\u001b[32m    663\u001b[39m     y_hat = np.apply_along_axis(\n\u001b[32m    664\u001b[39m         samplerate.resample, axis=axis, arr=y, ratio=ratio, converter_type=res_type\n\u001b[32m    665\u001b[39m     )\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m res_type.startswith(\u001b[33m\"\u001b[39m\u001b[33msoxr\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    667\u001b[39m     \u001b[38;5;66;03m# Use numpy to vectorize the resampler along the target axis\u001b[39;00m\n\u001b[32m    668\u001b[39m     \u001b[38;5;66;03m# This is because soxr does not support ndim>2 generally.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m     y_hat = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_along_axis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43msoxr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43min_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43morig_sr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mout_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m=\u001b[49m\u001b[43mres_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    678\u001b[39m     y_hat = resampy.resample(y, orig_sr, target_sr, \u001b[38;5;28mfilter\u001b[39m=res_type, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\shape_base.py:379\u001b[39m, in \u001b[36mapply_along_axis\u001b[39m\u001b[34m(func1d, axis, arr, *args, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    377\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mCannot apply_along_axis when any iteration dimensions are 0\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    378\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m res = asanyarray(\u001b[43mfunc1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minarr_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind0\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    381\u001b[39m \u001b[38;5;66;03m# build a buffer for storing evaluations of func1d.\u001b[39;00m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# remove the requested axis, and add the new ones on the end.\u001b[39;00m\n\u001b[32m    383\u001b[39m \u001b[38;5;66;03m# laid out so that each write is contiguous.\u001b[39;00m\n\u001b[32m    384\u001b[39m \u001b[38;5;66;03m# for a tuple index inds, buff[inds] = func1d(inarr_view[inds])\u001b[39;00m\n\u001b[32m    385\u001b[39m buff = zeros(inarr_view.shape[:-\u001b[32m1\u001b[39m] + res.shape, res.dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\soxr\\__init__.py:206\u001b[39m, in \u001b[36mresample\u001b[39m\u001b[34m(x, in_rate, out_rate, quality)\u001b[39m\n\u001b[32m    203\u001b[39m q = _quality_to_enum(quality)\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     y = \u001b[43mdivide_proc\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.squeeze(y, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m x.ndim == \u001b[32m2\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Loading and Testing Test Data\"\"\"\n",
    "print(\"---Extracting Test Data---\")\n",
    "\n",
    "test = []\n",
    "test_features = []\n",
    "num_test = len(os.listdir(f\"{dataset_directory}/Test\"))\n",
    "checkpoints = []\n",
    "for i in range(5):\n",
    "    checkpoints.append(round(i*num_test/4))\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(f\"{dataset_directory}/Test\")):\n",
    "    for num in checkpoints:\n",
    "        if i == num:\n",
    "            print(f\"Extraction {int(100*checkpoints.index(num)/4)}% complete\")\n",
    "    file_path = f\"{dataset_directory}/Test/{file_name}\"\n",
    "    the_thing = extract_features(file_path)\n",
    "    if the_thing is not None:\n",
    "        test_features.append(the_thing.reshape(1, -1))\n",
    "        print(the_thing.reshape(1, -1).shape)\n",
    "\n",
    "\n",
    "\n",
    "print(\"---Making Predictions---\")\n",
    "            \n",
    "# Convert list of arrays into a single numpy array\n",
    "test_features_stacked = np.vstack(test_features)\n",
    "test_scaled = scaler.transform(test_features_stacked)\n",
    "test_pca = pca.transform(test_scaled)\n",
    "\n",
    "# Predict using the SVM (with decoded predictions)\n",
    "test_pred = svm_clf.predict(test_pca)\n",
    "test_pred_labels = label_encoder.inverse_transform(test_pred)\n",
    "\n",
    "# Save to a CSV for submission to Kaggle\n",
    "with open(\"svm_pre-RFE.csv\", 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"filename\", \"emotion\"])\n",
    "    for i, emotion in enumerate(test_pred_labels):\n",
    "        writer.writerow([f\"{str(i+1)}.wav\", emotion])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91c9067",
   "metadata": {},
   "source": [
    "RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c3626",
   "metadata": {},
   "source": [
    "Extracting Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067edf8e",
   "metadata": {},
   "source": [
    "Training Model w/ Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43009380",
   "metadata": {},
   "source": [
    "Extracting Test Data and Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063501fe",
   "metadata": {},
   "source": [
    "RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model w/ Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Test Data and Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80180d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 1692 features.\n",
      "Fitting estimator with 1192 features.\n",
      "Fitting estimator with 692 features.\n",
      "Validation Accuracy: 0.5928571428571429\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. StandardScaler expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 80\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     79\u001b[39m     features, labels = load_data(\u001b[33m\"\u001b[39m\u001b[33mtrain_features.npy\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtrain_labels.npy\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[43mtrain_svm_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[33;03m\"\"\"Note on Overfitting:\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[33;03mNote how we tried to mitigate the overfitting problem explicitly at the end through RFE but also implicitly at several prior points in the data science pipeline. We used PCA to capture 95% variance and thus eliminate highly specfic dimensions in feature space that could potentially cause the model to overfit. We also used K-fold cross validation instead of a simple train test split in order to not make training dependent on just one random split of the available data.\u001b[39;00m\n\u001b[32m     85\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    104\u001b[39m \u001b[33;03m* Submission file format: Please be aware of the format and follow the format given on Kaggle of two columns with the same column names and format with the emotions having the first letter capitalized.\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mtrain_svm_classifier\u001b[39m\u001b[34m(features, labels)\u001b[39m\n\u001b[32m     62\u001b[39m joblib.dump(rfe, \u001b[33m\"\u001b[39m\u001b[33mmodel/rfe_selector_optimal.joblib\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Idk how to use joblibs so here you go\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Predict using the SVM (with decoded predictions)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m RFE_test_scaled = \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m RFE_test_transformed = rfe.transform(RFE_test_scaled)\n\u001b[32m     68\u001b[39m RFE_test_pred = model.predict(RFE_test_transformed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1062\u001b[39m, in \u001b[36mStandardScaler.transform\u001b[39m\u001b[34m(self, X, copy)\u001b[39m\n\u001b[32m   1059\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1061\u001b[39m copy = copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparse.issparse(X):\n\u001b[32m   1074\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.with_mean:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1101\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1096\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1097\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdtype=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mnumeric\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1098\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1099\u001b[39m     )\n\u001b[32m   1100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array.ndim >= \u001b[32m3\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m   1107\u001b[39m     _assert_all_finite(\n\u001b[32m   1108\u001b[39m         array,\n\u001b[32m   1109\u001b[39m         input_name=input_name,\n\u001b[32m   1110\u001b[39m         estimator_name=estimator_name,\n\u001b[32m   1111\u001b[39m         allow_nan=ensure_all_finite == \u001b[33m\"\u001b[39m\u001b[33mallow-nan\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1112\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found array with dim 3. StandardScaler expected <= 2."
     ]
    }
   ],
   "source": [
    "\"\"\"Reducing Overfitting through Recursive Feature Extraction (RFE)\n",
    "\n",
    "RFE is a feature selection method that fits a model with the\n",
    "existing features and removes the weakest feature. This fitting process is repeated until a specified\n",
    "number of features remains. In this case, the model is initially fit with all the combined features. RFE ranks the features by their importance to the predictive accuracy. The least important\n",
    "feature is removed recursively. The model is then refitted with the new, reduced set of features. This\n",
    "process is iterated until the specified number of features is reached.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_data(features_path, labels_path):\n",
    "    # Load features and original labels\n",
    "    features = np.load(features_path)\n",
    "    original_labels = np.load(labels_path)\n",
    "    return features, original_labels\n",
    "\n",
    "def train_svm_classifier(features, labels):\n",
    "    scaler = StandardScaler()\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    # Encode labels and scale features\n",
    "    labels_encoded = encoder.fit_transform(labels)\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(features_scaled, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Determine if you should use the dual formulation\n",
    "    use_dual = X_train.shape[0] > X_train.shape[1]  # True if more samples than features\n",
    "\n",
    "    # Initialize the LinearSVC model for RFE\n",
    "    linear_svc = LinearSVC(dual=use_dual, max_iter=20000, tol=1e-4)\n",
    "\n",
    "    # Feature selection with RFE using LinearSVC\n",
    "    rfe = RFE(estimator=linear_svc, n_features_to_select=192, step=500, verbose=3)\n",
    "    rfe.fit(X_train, y_train)\n",
    "\n",
    "    # Transform features using RFE\n",
    "    X_train_rfe = rfe.transform(X_train)\n",
    "    X_val_rfe = rfe.transform(X_val)\n",
    "\n",
    "    # Train the final model using the RBF kernel with selected features\n",
    "    model = SVC(kernel=\"rbf\", C=1, decision_function_shape=\"ovo\", gamma=\"scale\")\n",
    "    model.fit(X_train_rfe, y_train)\n",
    "\n",
    "    # Predict on the validation set with the reduced feature set\n",
    "    y_pred = model.predict(X_val_rfe)\n",
    "    validation_accuracy = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Validation Accuracy: {validation_accuracy}\")\n",
    "\n",
    "    # Save the best model, scaler, encoder, and RFE selector\n",
    "    joblib.dump(model, \"model/svm_model_optimal_rfe.joblib\")\n",
    "    joblib.dump(scaler, \"model/scaler_optimal_rfe.joblib\")\n",
    "    joblib.dump(encoder, \"model/label_encoder_optimal_rfe.joblib\")\n",
    "    joblib.dump(rfe, \"model/rfe_selector_optimal.joblib\")\n",
    "\n",
    "    # Idk how to use joblibs so here you go\n",
    "    # Predict using the SVM (with decoded predictions)\n",
    "    RFE_test_scaled = scaler.transform(test_features)\n",
    "    RFE_test_transformed = rfe.transform(RFE_test_scaled)\n",
    "    RFE_test_pred = model.predict(RFE_test_transformed)\n",
    "    RFE_test_pred_labels = encoder.inverse_transform(RFE_test_pred)\n",
    "\n",
    "    # Save to a CSV for submission to Kaggle\n",
    "    with open(\"svm_post-RFE.csv\", 'w', newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"filename\", \"emotion\"])\n",
    "        for i, emotion in enumerate(RFE_test_pred_labels):\n",
    "            writer.writerow([f\"{str(i+1)}.wav\", emotion])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    features, labels = load_data(\"train_features.npy\", \"train_labels.npy\")\n",
    "    train_svm_classifier(features, labels)\n",
    "\n",
    "\n",
    "\"\"\"Note on Overfitting:\n",
    "Note how we tried to mitigate the overfitting problem explicitly at the end through RFE but also implicitly at several prior points in the data science pipeline. We used PCA to capture 95% variance and thus eliminate highly specfic dimensions in feature space that could potentially cause the model to overfit. We also used K-fold cross validation instead of a simple train test split in order to not make training dependent on just one random split of the available data.\n",
    "\n",
    "Other Ways to Address Overfitting:\n",
    "* Splitting train validation ratio: The dataset this year is pretty large. The typical train validation split is 80% and 20%. You can always experiment with different ratios to find better performance. However, increasing or decreasing one side too much can lead to overfitting too much to the validation data or underfitting to the validation data.\n",
    "* Grid search vs random search:\n",
    "  * Both are ways to tune hyperparameters of your model for better performance. However, both have benefits and downsides.\n",
    "  * Grid search tries all combinations of hyperparameters in the range of values that you provide. Random search randomly samples hyperparameters in the range of values that you provide.\n",
    "  * General fast rule of thumb: Use grid search when there are less hyperparameters that also have more correlation with each other. Use random search when there are too many parameters without correlation with each other to see better trends first.\n",
    "* Early stopping: Use a plot to monitor the validation set performance. When the validation stops improving is when you stop training the model early before it reaches the end of the whole training iterations specified.\n",
    "* Regularization: Introduce a penalty term in the loss function that prevents over-emphasis and weights on a specific parameter. Different regularization methods were covered in class: L1 (Lasso) and L2 (Ridge).\n",
    "* Data augmentation: Create more data that is slightly changed from the given train set if you feel you want more training data.\n",
    "* Too many features: feature selection and dimensionality reduction like PCA.\n",
    "\n",
    "Other general tips:\n",
    "*   Consider using raw audio signals vs extracted features of audio signals vs images to train your models.\n",
    "*   Consider the implications about your data based on the test accuracies of models. For example, if your SVM has a poor accuracy (despite correct implementation), then that most likely implies that your data is probably ont linearly separable. In that case try using kernels or even better for your second model - neural nets!\n",
    "* CNNs (very common for such tasks, although not SOTA) can be used on 1D (WaveNet), 2D (ResNet), or 3D data (many times people assume it's only for 2D images).\n",
    "* Transformers are SOTA but take very long to train, especially with Colab's free GPU, so keep that in mind.\n",
    "* Loading Labels (IMPORTANT): The data for this year has each emotion and their files in a separate folder each without a created train.csv to download. So, please create a train.csv with one column being the filename and second column being the corresponding emotion based on which folder the file is in.\n",
    "  * NOTE: the emotion \"Surprised\" is spelled as \"Suprised\" so use \"Suprised\" across everything\n",
    "* Submission file format: Please be aware of the format and follow the format given on Kaggle of two columns with the same column names and format with the emotions having the first letter capitalized.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
