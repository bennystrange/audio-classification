{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "GCXIyzo-lwAx",
   "metadata": {
    "id": "GCXIyzo-lwAx"
   },
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d0e628",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27627,
     "status": "ok",
     "timestamp": 1745209727682,
     "user": {
      "displayName": "Matthew Nutt",
      "userId": "01284318922524244496"
     },
     "user_tz": 300
    },
    "id": "f2d0e628",
    "outputId": "c0861590-4805-4e22-c620-f0695e8e555c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from scipy.signal import welch\n",
    "from scipy.fft import fft, fftfreq\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# in theory, this should automagically detect whether or not you're in colab and set the directory accordingly\n",
    "# if in colab, put link to shared 378final folder in My Drive\n",
    "# if local, make a dataset folder containing the .wav folders in the same directory as the .py file\n",
    "# we won't track dataset folder on Git because it's 2GB Lol.\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    dataset_directory = \"/content/drive/My Drive/378final/dataset\"\n",
    "except:\n",
    "    dataset_directory = \"./dataset\"\n",
    "\n",
    "N_MFCC = 24\n",
    "\n",
    "# Hardcoded labels\n",
    "labels = [\"Angry\", \"Disgusted\", \"Fearful\", \"Happy\", \"Neutral\", \"Sad\", \"Suprised\"]\n",
    "# Numpy array makes it easier to make a list from a list of indices\n",
    "labels = np.array(labels)\n",
    "# Global scaler for feature scaling\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d6f78",
   "metadata": {
    "id": "837d6f78"
   },
   "source": [
    "Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e44596",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 29918,
     "status": "ok",
     "timestamp": 1745209757603,
     "user": {
      "displayName": "Matthew Nutt",
      "userId": "01284318922524244496"
     },
     "user_tz": 300
    },
    "id": "e0e44596",
    "outputId": "f470f7e8-092e-4010-ccb5-d9363a5170de"
   },
   "outputs": [],
   "source": [
    "\"\"\"Data Exploration\"\"\"\n",
    "\n",
    "# we would like to get a sense of the signal's properties so see what are some good features to extract\n",
    "#j = 1\n",
    "#for emotion in labels:\n",
    "emotion = \"Angry\"\n",
    "for j in range(1, 4):\n",
    "    file_path = f\"{dataset_directory}/{emotion}/{emotion}{j}.wav\"\n",
    "    audio, sampling_rate = librosa.load(file_path, sr=16000)  # load full audio signal\n",
    "\n",
    "    fig,axs = plt.subplots(3,2)\n",
    "\n",
    "    # raw audio waveform\n",
    "    axs[0,0].plot([i/sampling_rate for i in range(audio.shape[0])], audio, color = \"green\")\n",
    "    axs[0,0].set_title(\"Waveform\")\n",
    "    axs[0,0].set_xlabel(\"Time (s)\")\n",
    "    axs[0,0].set_ylabel(\"Amplitude\")\n",
    "    axs[0,0].grid()\n",
    "\n",
    "    # fft\n",
    "    N = len(audio)\n",
    "    yf = fft(audio)\n",
    "    xf = fftfreq(N, 1 / sampling_rate)[:N // 2]\n",
    "    axs[0,1].plot(xf, 2.0 / N * np.abs(yf[0:N // 2]), color = \"blue\")\n",
    "    axs[0,1].set_title(\"FFT\")\n",
    "    axs[0,1].set_xlabel(\"Frequency (Hz)\")\n",
    "    axs[0,1].set_ylabel(\"Amplitude\")\n",
    "    axs[0,1].grid()\n",
    "    axs[0,1].set_xscale(\"log\")\n",
    "\n",
    "    # psd\n",
    "    f, Pxx = welch(audio, sampling_rate, nperseg=1024)\n",
    "    axs[1,0].set_title(\"PSD\")\n",
    "    axs[1,0].set_xlabel(\"Frequency (Hz)\")\n",
    "    axs[1,0].set_ylabel(\"Power Spectral Density\")\n",
    "    axs[1,0].grid()\n",
    "    axs[1,0].semilogy(f, Pxx, color = \"orange\")\n",
    "    axs[1,0].set_xscale(\"log\")\n",
    "\n",
    "    # mfcc\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sampling_rate, n_mels=128) #can experiment with n_mels (try 22-128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mfccs = librosa.feature.mfcc(S=mel_spec_db, sr=sampling_rate, n_mfcc=N_MFCC) #experiment with n_mfcc?? (8-20)\n",
    "\n",
    "    delta_mfccs  = librosa.feature.delta(mfccs)\n",
    "    delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "\n",
    "    axs[1,1].imshow(mfccs, cmap=\"hot\", interpolation=\"nearest\", origin=\"lower\")\n",
    "    axs[1,1].set_title(\"MFCCs\")\n",
    "    axs[1,1].set_xlabel(\"Time\")\n",
    "    axs[1,1].set_ylabel(\"MFCC Coefficients\")\n",
    "\n",
    "    axs[2,0].imshow(delta_mfccs, cmap=\"hot\", interpolation=\"nearest\", origin=\"lower\")\n",
    "    axs[2,0].set_title(\"Derivative of MFCCs\")\n",
    "    axs[2,0].set_xlabel(\"Time\")\n",
    "    axs[2,0].set_ylabel(\"MFCC Coefficients\")\n",
    "\n",
    "    axs[2,1].imshow(delta2_mfccs, cmap=\"hot\", interpolation=\"nearest\", origin=\"lower\")\n",
    "    axs[2,1].set_title(\"Second Derivative of MFCCs\")\n",
    "    axs[2,1].set_xlabel(\"Time\")\n",
    "    axs[2,1].set_ylabel(\"MFCC Coefficients\")\n",
    "\n",
    "    # show all at once\n",
    "    fig.suptitle(f\"Features of {emotion}{j}.wav\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639a729",
   "metadata": {
    "id": "5639a729"
   },
   "source": [
    "Feature Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc81121",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1745209757606,
     "user": {
      "displayName": "Matthew Nutt",
      "userId": "01284318922524244496"
     },
     "user_tz": 300
    },
    "id": "bbc81121"
   },
   "outputs": [],
   "source": [
    "\"\"\"Feature Extraction (per audio signal)\"\"\"\n",
    "def extract_features(file_path, standard_audio_size=3):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        # Apparently the sampling rate differs between files, so we fix it here\n",
    "        audio, sampling_rate = librosa.load(file_path, sr=16000)\n",
    "\n",
    "        # Pad/truncate to get standard length (so features are consistent length)\n",
    "        padded_audio = librosa.util.fix_length(audio, size=standard_audio_size*sampling_rate)\n",
    "\n",
    "        # Extract features\n",
    "        mel_spec = librosa.feature.melspectrogram(y=padded_audio, sr=sampling_rate, n_mels=128, hop_length=1024, n_fft=4096)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        mfccs = librosa.feature.mfcc(S=mel_spec_db, sr=sampling_rate, n_mfcc=N_MFCC)\n",
    "        delta_mfccs  = librosa.feature.delta(mfccs)\n",
    "        delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "\n",
    "        all_features = np.vstack([mfccs, delta_mfccs, delta2_mfccs]).flatten(order='F')\n",
    "        return all_features\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183888af",
   "metadata": {
    "id": "183888af"
   },
   "source": [
    "Extracting Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b4b443",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181451,
     "status": "ok",
     "timestamp": 1745209939052,
     "user": {
      "displayName": "Matthew Nutt",
      "userId": "01284318922524244496"
     },
     "user_tz": 300
    },
    "id": "19b4b443",
    "outputId": "589f999a-05fb-4f82-9c0b-59ffecec06a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Extracting Train Data---\n",
      "Extracting: Angry\n",
      "Extracting: Disgusted\n",
      "Extracting: Fearful\n",
      "Extracting: Happy\n",
      "Extracting: Neutral\n",
      "Extracting: Sad\n",
      "Extracting: Suprised\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Extracting Train Data\"\"\"\n",
    "print(\"---Extracting Train Data---\")\n",
    "\n",
    "# Load dataset and extract features\n",
    "training_samples = []\n",
    "training_labels = []\n",
    "\n",
    "for label in labels:\n",
    "    print(f\"Extracting: {label}\")\n",
    "    file_names = os.listdir(f\"{dataset_directory}/{label}\")\n",
    "    #random.shuffle(file_names)\n",
    "    for num, file_name in enumerate(file_names):\n",
    "        file_path = f\"{dataset_directory}/{label}/{file_name}\"\n",
    "        training_sample = extract_features(file_path)\n",
    "        if training_sample is not None:\n",
    "            training_samples.append(training_sample)\n",
    "            training_labels.append(label)\n",
    "\n",
    "# Convert to numpy array, scale features\n",
    "training_samples = np.array(training_samples)\n",
    "training_samples_scaled = scaler.fit_transform(training_samples)\n",
    "\n",
    "# Encode labels\n",
    "training_labels = np.array(training_labels)\n",
    "training_labels_encoded = [labels.tolist().index(label) for label in training_labels]\n",
    "training_labels_encoded = np.array(training_labels_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d351a6d0",
   "metadata": {},
   "source": [
    "Extracting Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de65188f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Extracting Test Data---\n",
      "25% complete\n",
      "50% complete\n",
      "75% complete\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Extracting Test Data\"\"\"\n",
    "print(\"---Extracting Test Data---\")\n",
    "\n",
    "# for status updates\n",
    "num_test = len(os.listdir(f\"{dataset_directory}/Test\"))\n",
    "checkpoints = []\n",
    "for i in range(1, 5):\n",
    "    checkpoints.append(round(i*num_test/4))\n",
    "\n",
    "test_samples = []\n",
    "test_nums = []\n",
    "for i, file_name in enumerate(os.listdir(f\"{dataset_directory}/Test\")):\n",
    "    for point in checkpoints:\n",
    "        if i == point:\n",
    "            print(f\"{int(25*(checkpoints.index(point)+1))}% complete\")\n",
    "    file_path = f\"{dataset_directory}/Test/{file_name}\"\n",
    "    test_sample = extract_features(file_path)\n",
    "    if test_sample is not None:\n",
    "        test_samples.append(test_sample)\n",
    "        test_nums.append(int(file_name.split('.')[0]))\n",
    "\n",
    "# Scale with same scaler as train data\n",
    "test_samples_sorted = [test_sample for _, test_sample in sorted(zip(test_nums, test_samples))]\n",
    "test_samples_sorted = np.array(test_samples_sorted)\n",
    "test_samples_scaled = scaler.transform(test_samples_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7134dd",
   "metadata": {
    "id": "8d7134dd"
   },
   "source": [
    "Training Model and Predicting (SVM w/ PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be87cd08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8578,
     "status": "ok",
     "timestamp": 1745209947626,
     "user": {
      "displayName": "Matthew Nutt",
      "userId": "01284318922524244496"
     },
     "user_tz": 300
    },
    "id": "be87cd08",
    "outputId": "b52dc4e1-6985-4dee-d2fe-501d8680ccc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Validating Model---\n",
      "Split #1\n",
      "Split #2\n",
      "Split #3\n",
      "Split #4\n",
      "Split #5\n",
      "Average Accuracy: 54.05%\n",
      "---Making Predictions---\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVM w/ PCA\"\"\"\n",
    "print(\"---Validating Model---\")\n",
    "# NOTE: It seems like the TAs wanted to reduce overfitting by using PCA. However, it also seems that, at least for the full dataset,\n",
    "#       leaving higher variance in the data results in better validation scores!\n",
    "#       And after some tests, turns out that not using PCA at all is slower, but nets a 20% accuracy bonus above 99% variance!\n",
    "\n",
    "# SVM Model, preprocessing, and cross-validation initialization\n",
    "pca_model = SVC()\n",
    "pca = PCA(n_components=0.9) # preserve x% of variance in data\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accuracies = []\n",
    "do_PCA = False\n",
    "\n",
    "# Perform cross-validation\n",
    "for i, (train_index, val_index) in enumerate(kf.split(training_samples_scaled, training_labels_encoded)):\n",
    "    print(f\"Split #{i+1}\")\n",
    "    X_train, X_val = training_samples_scaled[train_index], training_samples_scaled[val_index]\n",
    "    y_train, y_val = training_labels_encoded[train_index], training_labels_encoded[val_index]\n",
    "    if do_PCA:\n",
    "        PCA_X_train = pca.fit_transform(X_train)\n",
    "        PCA_X_val = pca.transform(X_val)\n",
    "    else:\n",
    "        PCA_X_train = X_train\n",
    "        PCA_X_val = X_val\n",
    "    pca_model.fit(PCA_X_train, y_train)\n",
    "    y_pred = pca_model.predict(PCA_X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Average Accuracy: {average_accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"---Making Predictions---\")\n",
    "\n",
    "# Transform features using PCA\n",
    "if do_PCA:\n",
    "    PCA_test_samples = pca.transform(test_samples_scaled)\n",
    "else:\n",
    "    PCA_test_samples = test_samples_scaled\n",
    "\n",
    "# Predict using the SVM (with decoded predictions)\n",
    "PCA_test_pred = pca_model.predict(PCA_test_samples)\n",
    "PCA_test_pred_labels = labels[PCA_test_pred]\n",
    "\n",
    "# Save to a CSV for submission to Kaggle\n",
    "with open(\"svm_PCA.csv\", 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"filename\", \"emotion\"])\n",
    "    for i, emotion in enumerate(PCA_test_pred_labels):\n",
    "        writer.writerow([f\"{i+1}.wav\", emotion])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h3dMu_S-lwBA",
   "metadata": {
    "id": "h3dMu_S-lwBA"
   },
   "source": [
    "Training Model and Predicting (SVM w/ RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80180d63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80180d63",
    "outputId": "d1337d2c-e328-4f54-9503-5db6ec2b7c31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Validating Model---\n",
      "Hyperparameters: 2779 training samples, 520 sample features, step size 10, first step 1100, tolerance 0.01\n",
      "Fitting estimator with 1692 features.\n",
      "Validation Accuracy: 0.7251798561151079\n",
      "Fitting estimator with 592 features.\n",
      "Validation Accuracy: 0.7237410071942446\n",
      "Fitting estimator with 582 features.\n",
      "Validation Accuracy: 0.7251798561151079\n",
      "Fitting estimator with 572 features.\n",
      "Validation Accuracy: 0.7251798561151079\n",
      "Fitting estimator with 562 features.\n",
      "Validation Accuracy: 0.7251798561151079\n",
      "Fitting estimator with 552 features.\n",
      "Validation Accuracy: 0.7280575539568346\n",
      "Fitting estimator with 542 features.\n",
      "Validation Accuracy: 0.7309352517985611\n",
      "Fitting estimator with 532 features.\n",
      "Validation Accuracy: 0.7309352517985611\n",
      "Fitting estimator with 522 features.\n",
      "Validation Accuracy: 0.7338129496402878\n",
      "---Making Predictions---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNote on Overfitting:\\nNote how we tried to mitigate the overfitting problem explicitly at the end through RFE but also implicitly at several prior points in the data science pipeline. We used PCA to capture 95% variance and thus eliminate highly specfic dimensions in feature space that could potentially cause the model to overfit. We also used K-fold cross validation instead of a simple train test split in order to not make training dependent on just one random split of the available data.\\n\\nOther Ways to Address Overfitting:\\n* Splitting train validation ratio: The dataset this year is pretty large. The typical train validation split is 80% and 20%. You can always experiment with different ratios to find better performance. However, increasing or decreasing one side too much can lead to overfitting too much to the validation data or underfitting to the validation data.\\n* Grid search vs random search:\\n    * Both are ways to tune hyperparameters of your model for better performance. However, both have benefits and downsides.\\n    * Grid search tries all combinations of hyperparameters in the range of values that you provide. Random search randomly samples hyperparameters in the range of values that you provide.\\n    * General fast rule of thumb: Use grid search when there are less hyperparameters that also have more correlation with each other. Use random search when there are too many parameters without correlation with each other to see better trends first.\\n* Early stopping: Use a plot to monitor the validation set performance. When the validation stops improving is when you stop training the model early before it reaches the end of the whole training iterations specified.\\n* Regularization: Introduce a penalty term in the loss function that prevents over-emphasis and weights on a specific parameter. Different regularization methods were covered in class: L1 (Lasso) and L2 (Ridge).\\n* Data augmentation: Create more data that is slightly changed from the given train set if you feel you want more training data.\\n* Too many features: feature selection and dimensionality reduction like PCA.\\n\\nOther general tips:\\n*   Consider using raw audio signals vs extracted features of audio signals vs images to train your models.\\n*   Consider the implications about your data based on the test accuracies of models. For example, if your SVM has a poor accuracy (despite correct implementation), then that most likely implies that your data is probably ont linearly separable. In that case try using kernels or even better for your second model - neural nets!\\n* CNNs (very common for such tasks, although not SOTA) can be used on 1D (WaveNet), 2D (ResNet), or 3D data (many times people assume it\\'s only for 2D images).\\n* Transformers are SOTA but take very long to train, especially with Colab\\'s free GPU, so keep that in mind.\\n* Loading Labels (IMPORTANT): The data for this year has each emotion and their files in a separate folder each without a created train.csv to download. So, please create a train.csv with one column being the filename and second column being the corresponding emotion based on which folder the file is in.\\n    * NOTE: the emotion \"Surprised\" is spelled as \"Suprised\" so use \"Suprised\" across everything\\n* Submission file format: Please be aware of the format and follow the format given on Kaggle of two columns with the same column names and format with the emotions having the first letter capitalized.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"SVM w/ RFE\"\"\"\n",
    "\n",
    "# sets whether or not to make a prediction after validation\n",
    "# intuitively, you'd do this separately and use the entire training dataset, but\n",
    "# i've seen that accuracy is highly dependent on number of samples\n",
    "# so it's helpful to have the reassurance of a good model before submitting\n",
    "PREDICT = True\n",
    "LOG = False\n",
    "\n",
    "N_FEATURES = 520\n",
    "STEP_SIZE = 10\n",
    "FIRST_STEP = 1100\n",
    "RFE_TOL = 0.05\n",
    "FINAL_TOL = 0.01\n",
    "\n",
    "\n",
    "\n",
    "print(\"---Validating Model---\")\n",
    "# Checks validation accuracy at each step along the way\n",
    "# Log name is <number of samples used to train - number of features to reduce to - step size(first step) - tolerance>.log\n",
    "if LOG: logfile = open(f\"./logs/{int(training_samples_scaled.shape[0]*0.8)}-{N_FEATURES}-{STEP_SIZE}({FIRST_STEP})-tol{RFE_TOL}.log\", 'x')\n",
    "print(f\"Hyperparameters: {int(training_samples_scaled.shape[0]*0.8)} training samples, {N_FEATURES} sample features, step size {STEP_SIZE}, first step {FIRST_STEP}, tolerance {FINAL_TOL}\")\n",
    "if LOG: logfile.write(f\"Hyperparameters: {int(training_samples_scaled.shape[0]*0.8)} training samples, {N_FEATURES} sample features, step size {STEP_SIZE}, first step {FIRST_STEP}, tolerance {FINAL_TOL}\\n\")\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "kf_gen = kf.split(training_samples_scaled, training_labels_encoded)\n",
    "train_index, val_index = next(kf_gen)\n",
    "X_train, X_val = training_samples_scaled[train_index], training_samples_scaled[val_index]\n",
    "y_train, y_val = training_labels_encoded[train_index], training_labels_encoded[val_index]\n",
    "\n",
    "# Initialize the models (linear_svc for RFE, model for post-RFE predictions)\n",
    "linear_svc = LinearSVC(max_iter=2000, tol=RFE_TOL)\n",
    "rfe_model = SVC(tol=FINAL_TOL)\n",
    "\n",
    "# Initialize continuous validation\n",
    "n_feat = X_train.shape[1]\n",
    "RFE_X_train = X_train\n",
    "RFE_X_val = X_val\n",
    "RFE_test_samples = np.copy(test_samples_scaled)\n",
    "\n",
    "while (n_feat > N_FEATURES):\n",
    "    \n",
    "    if (n_feat == X_train.shape[1]):\n",
    "        n_feat -= FIRST_STEP\n",
    "        is_first_step = True\n",
    "    elif (n_feat - STEP_SIZE > N_FEATURES):\n",
    "        n_feat -= STEP_SIZE\n",
    "        is_first_step = False\n",
    "    else:\n",
    "        n_feat = N_FEATURES\n",
    "        is_first_step = False\n",
    "    \n",
    "    # Feature selection with RFE using LinearSVC\n",
    "    if LOG: logfile.write(f\"Reducing from {RFE_X_train.shape[1]} to {n_feat} features\\n\")\n",
    "    if is_first_step:\n",
    "        rfe = RFE(estimator=linear_svc, n_features_to_select=n_feat, step=FIRST_STEP, verbose=3)\n",
    "    else:\n",
    "        rfe = RFE(estimator=linear_svc, n_features_to_select=n_feat, step=STEP_SIZE, verbose=3)\n",
    "    rfe.fit(RFE_X_train, y_train)\n",
    "\n",
    "    # Transform features using RFE\n",
    "    RFE_X_train = rfe.transform(RFE_X_train)\n",
    "    RFE_X_val = rfe.transform(RFE_X_val)\n",
    "    RFE_test_samples = rfe.transform(RFE_test_samples)\n",
    "\n",
    "    # Train the final model using the RBF kernel with selected features\n",
    "    rfe_model.fit(RFE_X_train, y_train)\n",
    "\n",
    "    # Predict on the validation set with the reduced feature set\n",
    "    y_pred = rfe_model.predict(RFE_X_val)\n",
    "    validation_accuracy = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Validation Accuracy: {validation_accuracy}\")\n",
    "    if LOG: logfile.write(f\"Validation Accuracy: {validation_accuracy}\\n\")\n",
    "\n",
    "if LOG: logfile.close()\n",
    "\n",
    "if PREDICT:\n",
    "    print(\"---Making Predictions---\")\n",
    "\n",
    "    # Predict using the SVM (with decoded predictions)\n",
    "    RFE_test_pred = rfe_model.predict(RFE_test_samples)\n",
    "    RFE_test_pred_labels = labels[RFE_test_pred]\n",
    "\n",
    "    # Save to a CSV for submission to Kaggle\n",
    "    with open(\"svm_RFE.csv\", 'w', newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"filename\", \"emotion\"])\n",
    "        for i, emotion in enumerate(RFE_test_pred_labels):\n",
    "            writer.writerow([f\"{i+1}.wav\", emotion])\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Note on Overfitting:\n",
    "Note how we tried to mitigate the overfitting problem explicitly at the end through RFE but also implicitly at several prior points in the data science pipeline. We used PCA to capture 95% variance and thus eliminate highly specfic dimensions in feature space that could potentially cause the model to overfit. We also used K-fold cross validation instead of a simple train test split in order to not make training dependent on just one random split of the available data.\n",
    "\n",
    "Other Ways to Address Overfitting:\n",
    "* Splitting train validation ratio: The dataset this year is pretty large. The typical train validation split is 80% and 20%. You can always experiment with different ratios to find better performance. However, increasing or decreasing one side too much can lead to overfitting too much to the validation data or underfitting to the validation data.\n",
    "* Grid search vs random search:\n",
    "    * Both are ways to tune hyperparameters of your model for better performance. However, both have benefits and downsides.\n",
    "    * Grid search tries all combinations of hyperparameters in the range of values that you provide. Random search randomly samples hyperparameters in the range of values that you provide.\n",
    "    * General fast rule of thumb: Use grid search when there are less hyperparameters that also have more correlation with each other. Use random search when there are too many parameters without correlation with each other to see better trends first.\n",
    "* Early stopping: Use a plot to monitor the validation set performance. When the validation stops improving is when you stop training the model early before it reaches the end of the whole training iterations specified.\n",
    "* Regularization: Introduce a penalty term in the loss function that prevents over-emphasis and weights on a specific parameter. Different regularization methods were covered in class: L1 (Lasso) and L2 (Ridge).\n",
    "* Data augmentation: Create more data that is slightly changed from the given train set if you feel you want more training data.\n",
    "* Too many features: feature selection and dimensionality reduction like PCA.\n",
    "\n",
    "Other general tips:\n",
    "*   Consider using raw audio signals vs extracted features of audio signals vs images to train your models.\n",
    "*   Consider the implications about your data based on the test accuracies of models. For example, if your SVM has a poor accuracy (despite correct implementation), then that most likely implies that your data is probably ont linearly separable. In that case try using kernels or even better for your second model - neural nets!\n",
    "* CNNs (very common for such tasks, although not SOTA) can be used on 1D (WaveNet), 2D (ResNet), or 3D data (many times people assume it's only for 2D images).\n",
    "* Transformers are SOTA but take very long to train, especially with Colab's free GPU, so keep that in mind.\n",
    "* Loading Labels (IMPORTANT): The data for this year has each emotion and their files in a separate folder each without a created train.csv to download. So, please create a train.csv with one column being the filename and second column being the corresponding emotion based on which folder the file is in.\n",
    "    * NOTE: the emotion \"Surprised\" is spelled as \"Suprised\" so use \"Suprised\" across everything\n",
    "* Submission file format: Please be aware of the format and follow the format given on Kaggle of two columns with the same column names and format with the emotions having the first letter capitalized.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab83bcbd",
   "metadata": {},
   "source": [
    "Plotting Validation Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plotting Validation Error\"\"\"\n",
    "# parse data from log, where x = features reduced to, and y = validation accuracy\n",
    "log_names = [\"./logs/1120-20-250.log\", \"./logs/2779-20-10(1000).log\", \"./logs/2779-400-10(1000)-tol0.01.log\", \"./logs/2779-400-10(1000)-tol0.05-z6.log\"]\n",
    "for log_name in log_names:\n",
    "    plotfile = open(log_name, 'r')\n",
    "    num_features_plot = []\n",
    "    accuracies_plot = []\n",
    "\n",
    "    for line in plotfile:\n",
    "        line = line.strip()\n",
    "        elems = line.split()\n",
    "        if len(elems) == 6: # if \"Reducing from\" line\n",
    "            num_features_plot.append(int(elems[4]))\n",
    "        elif len(elems) == 3: # if \"Validation accuracy\" line\n",
    "            accuracies_plot.append(float(elems[2]))\n",
    "        else: # if first line\n",
    "            plt.title(line)\n",
    "\n",
    "    plotfile.close()\n",
    "\n",
    "    plt.plot(num_features_plot, accuracies_plot)\n",
    "    plt.xlabel(\"Number of Features\")\n",
    "    plt.ylabel(\"Validation Accuracy\")\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968ec2f6",
   "metadata": {},
   "source": [
    "2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e91847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1440</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,087</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m1,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m73,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m18,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1440\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │        \u001b[38;5;34m10,087\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,623</span> (404.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m103,623\u001b[0m (404.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,623</span> (404.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,623\u001b[0m (404.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 215ms/step - loss: 1.6643\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step\n",
      "Validation Accuracy: 52.17%\n",
      "Epoch 2/2\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 222ms/step - loss: 1.2214\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step\n",
      "Validation Accuracy: 56.95%\n",
      "Epoch 3/3\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 242ms/step - loss: 1.0814\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step\n",
      "Validation Accuracy: 57.39%\n",
      "Epoch 4/4\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 250ms/step - loss: 0.9968\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step\n",
      "Validation Accuracy: 60.27%\n",
      "Epoch 5/5\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 247ms/step - loss: 0.9137\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step\n",
      "Validation Accuracy: 60.81%\n",
      "Epoch 6/6\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 248ms/step - loss: 0.8679\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step\n",
      "Validation Accuracy: 62.42%\n",
      "Epoch 7/7\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 244ms/step - loss: 0.8238\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step\n",
      "Validation Accuracy: 63.88%\n",
      "Epoch 8/8\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 243ms/step - loss: 0.7849\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step\n",
      "Validation Accuracy: 63.79%\n",
      "Epoch 9/9\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 243ms/step - loss: 0.7553\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n",
      "Validation Accuracy: 62.81%\n",
      "Epoch 10/10\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 253ms/step - loss: 0.7007\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step\n",
      "Validation Accuracy: 62.66%\n",
      "---Making Predictions---\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_1/flatten_1/Reshape defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 618, in run_forever\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1951, in _run_once\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3362, in run_cell_async\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3607, in run_ast_nodes\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3667, in run_code\n\n  File \"C:\\Users\\Matthew\\AppData\\Local\\Temp\\ipykernel_6852\\1416575779.py\", line 70, in <module>\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 560, in predict\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 259, in one_step_on_data_distributed\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 249, in one_step_on_data\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 104, in predict_step\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 910, in __call__\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 58, in __call__\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 221, in call\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 183, in call\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 643, in call\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 910, in __call__\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 58, in __call__\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py\", line 54, in call\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 4937, in reshape\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 2024, in reshape\n\nOnly one input size may be -1, not both 0 and 1\n\t [[{{node sequential_1/flatten_1/Reshape}}]] [Op:__inference_one_step_on_data_distributed_30311]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Predict using the CNN (with decoded predictions)\u001b[39;00m\n\u001b[32m     69\u001b[39m test_samples_2D = test_samples_scaled.reshape((test_samples_scaled.shape[\u001b[32m0\u001b[39m], \u001b[32m36\u001b[39m, -\u001b[32m1\u001b[39m), order=\u001b[33m'\u001b[39m\u001b[33mF\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m CNN_test_pred_prob = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_samples_2D\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m CNN_test_pred = np.argmax(CNN_test_pred_prob, axis=\u001b[32m1\u001b[39m)\n\u001b[32m     72\u001b[39m CNN_test_pred_labels = labels[CNN_test_pred]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Graph execution error:\n\nDetected at node sequential_1/flatten_1/Reshape defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 618, in run_forever\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1951, in _run_once\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3362, in run_cell_async\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3607, in run_ast_nodes\n\n  File \"C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3667, in run_code\n\n  File \"C:\\Users\\Matthew\\AppData\\Local\\Temp\\ipykernel_6852\\1416575779.py\", line 70, in <module>\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 560, in predict\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 259, in one_step_on_data_distributed\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 249, in one_step_on_data\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 104, in predict_step\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 910, in __call__\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 58, in __call__\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 221, in call\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 183, in call\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 643, in call\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 910, in __call__\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 58, in __call__\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py\", line 54, in call\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 4937, in reshape\n\n  File \"c:\\Users\\Matthew\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 2024, in reshape\n\nOnly one input size may be -1, not both 0 and 1\n\t [[{{node sequential_1/flatten_1/Reshape}}]] [Op:__inference_one_step_on_data_distributed_30311]"
     ]
    }
   ],
   "source": [
    "\"\"\"2D CNN\"\"\"\n",
    "\n",
    "NUM_EPOCH = 10\n",
    "\n",
    "from tensorflow.keras import Sequential, losses\n",
    "# Figure out what kind of pooling method is best (Max, average, or sum )\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# reshape training data to 2D, labels to one-hot\n",
    "training_samples_2D = training_samples_scaled.reshape((training_samples_scaled.shape[0], 3*N_MFCC, -1), order='F')\n",
    "training_labels_onehot = np.zeros((training_labels_encoded.shape[0], 7))\n",
    "for num, row in enumerate(training_labels_onehot):\n",
    "    row[training_labels_encoded[num]] = 1\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "kf_gen = kf.split(training_samples_2D, training_labels_encoded)\n",
    "train_index, val_index = next(kf_gen)\n",
    "X_train, X_val = training_samples_2D[train_index], training_samples_2D[val_index]\n",
    "y_train, y_val = training_labels_onehot[train_index], training_labels_encoded[val_index]\n",
    "\n",
    "# each filter performs its own convolution, the more filters, the more features we can detect\n",
    "# better to to have more feature detection early on before reducing dimensions via pooling\n",
    "filter_count_layer1 = 128\n",
    "filter_count_layer2 = 64\n",
    "filter_count_layer3 = 32\n",
    "# smaller filter size, is more accurate but takes more training time and could lead to overfitting\n",
    "filter_shape = (3,3)\n",
    "# the percentage of neurons we want to set zero to prevent overfitting (need to tune this)\n",
    "dropout_ratio = 0.2\n",
    "model = Sequential()\n",
    "\n",
    "# 'same' padding implies padding the image wih zeros to make the filter fit\n",
    "model.add(Conv2D(filter_count_layer1, filter_shape, padding='same', activation='relu', input_shape=(training_samples_2D.shape[1], training_samples_2D.shape[2], 1)))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "# gets the maximum value of each 2x2 region to reduce dimensionality\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filter_count_layer2, filter_shape, padding='same', activation='relu'))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filter_count_layer3, filter_shape, padding='same', activation='relu'))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 7 output categories\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss=losses.CategoricalCrossentropy())\n",
    "\n",
    "# train model\n",
    "for num in range(NUM_EPOCH):\n",
    "    model.fit(X_train, y_train, epochs=(num+1), initial_epoch=num)\n",
    "\n",
    "    # Check validation accuracy\n",
    "    y_pred_prob = model.predict(X_val)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"---Making Predictions---\")\n",
    "\n",
    "# Predict using the CNN (with decoded predictions)\n",
    "test_samples_2D = test_samples_scaled.reshape((test_samples_scaled.shape[0], N_MFCC*3, -1), order='F')\n",
    "CNN_test_pred_prob = model.predict(test_samples_2D)\n",
    "CNN_test_pred = np.argmax(CNN_test_pred_prob, axis=1)\n",
    "CNN_test_pred_labels = labels[CNN_test_pred]\n",
    "\n",
    "# Save to a CSV for submission to Kaggle\n",
    "with open(\"svm_CNN.csv\", 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"filename\", \"emotion\"])\n",
    "    for i, emotion in enumerate(CNN_test_pred_labels):\n",
    "        writer.writerow([f\"{i+1}.wav\", emotion])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
