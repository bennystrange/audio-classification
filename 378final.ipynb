{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d0e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "from scipy.fft import fft, fftfreq\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    dataset_directory = \"/content/drive/My Drive/378final/dataset\"\n",
    "except:\n",
    "    dataset_directory = \"./dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d6f78",
   "metadata": {},
   "source": [
    "Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e44596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Data Exploration (FFT & PSD)\"\"\"\n",
    "\n",
    "# Hardcoded labels\n",
    "labels = [\"Angry\", \"Disgusted\", \"Fearful\", \"Happy\", \"Neutral\", \"Sad\", \"Suprised\"]\n",
    "\n",
    "\"\"\"\n",
    "# we would like to get a sense of the signal's properties so see what are some good features to extract\n",
    "for i in range(len(labels)):\n",
    "    file_name = f\"/content/drive/My Drive/378final/Dataset/train/train{str(i).zfill(3)}.wav\"\n",
    "    y, sr = librosa.load(file_name, sr=None)  # load full audio signal\n",
    "\n",
    "    # raw audio waveform\n",
    "    # Plot the waveform\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    librosa.display.waveshow(y, sr=sr, color = \"green\")\n",
    "    plt.title(\"Audio Time Series (Waveform)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    # fft\n",
    "    N = len(y)\n",
    "    yf = fft(y)\n",
    "    xf = fftfreq(N, 1 / sr)[:N // 2]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(xf, 2.0 / N * np.abs(yf[0:N // 2]), color = \"blue\")\n",
    "    plt.title(f\"FFT of File {i}\")\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # psd\n",
    "    f, Pxx = welch(y, sr, nperseg=1024)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.semilogy(f, Pxx, color = \"orange\")\n",
    "    plt.title(f\"PSD of File {i}\")\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Power Spectral Density\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The basic data exploration above provides intuition for extracting features or processing raw data to be in a different format that might allow for better ML models (think linear separability).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc81121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature Extraction (per audio signal)\n",
    "\"\"\"\n",
    "def extract_features(file_path, standard_audio_size=4):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        # Apparently the sampling rate differs between files, so we fix it here\n",
    "        audio, sampling_rate = librosa.load(file_path, sr=8000)\n",
    "\n",
    "        # Pad/truncate to get standard length (so features are consistent length)\n",
    "        padded_audio = librosa.util.fix_length(audio, size=standard_audio_size*sampling_rate)\n",
    "\n",
    "        # Extract features\n",
    "        fft_coeffs = fft(padded_audio)\n",
    "        # fft_freqs = fftfreq(standard_audio_size*sampling_rate, 1 / sampling_rate)\n",
    "        #mfccs = librosa.feature.mfcc(y=audio_timeseries, sr=sampling_rate, n_mfcc=512)\n",
    "        #melspec = gen_melspec(file, n_mels=)\n",
    "        #chroma = librosa.feature.chroma_stft(y=audio_timeseries, sr=sampling_rate)\n",
    "        # all_features = np.vstack([fft_coeffs])\n",
    "        all_features = np.abs(fft_coeffs)\n",
    "        #librosa_features_mean = np.mean(all_features, axis=1)\n",
    "        return all_features\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "#Note: This is just a small sample of all the features you can extract from audio signals. Look at what the librosa library has to offer!\n",
    "#Another Note: This is an example of feature extraction per data point (signal). You could also do something like PCA on all the raw\n",
    "#               train data (as in directly on the audio signals) or PCA on all data as the computed features per datapoint.\n",
    "\n",
    "#Audio as Melspectograms (Hint Hint for CNNs, other image classifiers)\n",
    "\n",
    "\"\"\"\n",
    "def gen_melspec(file, n_mels=32):\n",
    "  audio_timeseries, sampling_rate = librosa.load(file, sr=None)\n",
    "  mel_spec = librosa.feature.melspectrogram(y=audio_timeseries, sr=sampling_rate, n_mels=n_mels)\n",
    "  log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "  return log_mel_spec.flatten()\n",
    "  # there are also other features that you can explore too!\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loading Features\"\"\"\n",
    "print(\"---Extracting Train Data---\")\n",
    "\n",
    "# Load dataset and extract features\n",
    "features = []\n",
    "labels_for_features = []\n",
    "\n",
    "for label in labels:\n",
    "    print(f\"Extracting: {label}\")\n",
    "    for num, file_name in enumerate(os.listdir(f\"{dataset_directory}/{label}\")):\n",
    "        #if (num < 100): # comment this out this to use ALL files\n",
    "            file_path = f\"{dataset_directory}/{label}/{file_name}\"\n",
    "            extracted_features = extract_features(file_path)\n",
    "            if extracted_features is not None:\n",
    "                features.append(extracted_features)\n",
    "                labels_for_features.append(label)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Model + Trainer\"\"\"\n",
    "print(\"---Training Model---\")\n",
    "\n",
    "# Convert to numpy arrays and continue as before\n",
    "features = np.array(features)\n",
    "labels_for_features = np.array(labels_for_features)\n",
    "#converts labels to unique integers\n",
    "#this may be optional\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels_for_features)\n",
    "\n",
    "#print(\"encoded labels\", labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be87cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "accuracies = []\n",
    "\n",
    "\"\"\"\n",
    "Alternatively, you can also simply use sklearn's train_test_split function!! Cross validation is K different random combinations\n",
    "of this train and test data split in order to train the model more robustly and ultimately use all your available data for the kaggle competition.\n",
    "\"\"\"\n",
    "\n",
    "# SVM Model and preprocessing initialization\n",
    "svm_clf = SVC(kernel=\"rbf\", C=1, gamma=\"auto\")\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=0.95) #keep enough components to preserve 95% of the variance in the data\n",
    "\n",
    "# Perform cross-validation\n",
    "for i, (train_index, test_index) in enumerate(kf.split(features, labels_encoded)):\n",
    "    print(f\"Split #{i+1}\")\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels_encoded[train_index], labels_encoded[test_index]\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    # NOTE: PCA IS A MAJOR SLOWDOWN! THE BIGGER THE DATASET, THE LONGER IT TAKES!\n",
    "    # fitting the svm is genuinely faster than the pca\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "    svm_clf.fit(X_train_pca, y_train)\n",
    "    y_pred = svm_clf.predict(X_test_pca)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Average Accuracy: {average_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca3c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loading and Testing Test Data\"\"\"\n",
    "print(\"---Extracting Test Data---\")\n",
    "\n",
    "test = []\n",
    "test_features = []\n",
    "num_test = len(os.listdir(f\"{dataset_directory}/Test\"))\n",
    "checkpoints = []\n",
    "for i in range(5):\n",
    "    checkpoints.append(round(i*num_test/4))\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(f\"{dataset_directory}/Test\")):\n",
    "    for num in checkpoints:\n",
    "        if i == num:\n",
    "            print(f\"Extraction {int(100*checkpoints.index(num)/4)}% complete\")\n",
    "    file_path = f\"{dataset_directory}/Test/{file_name}\"\n",
    "    the_thing = extract_features(file_path)\n",
    "    if the_thing is not None:\n",
    "        test_features.append(the_thing.reshape(1, -1))\n",
    "\n",
    "\"\"\"\n",
    "for i in range(20):  # Assuming 20 test files\n",
    "    file_name = f\"/content/drive/My Drive/Elec378 Final Project/Dataset/test/test{str(i).zfill(3)}.wav\"\n",
    "    for j in range(segments_per_file):\n",
    "        start_second = j * segment_duration\n",
    "        mfccs = extract_features(file_name, start_second, duration=segment_duration)\n",
    "        if mfccs is not None:\n",
    "            #2D array shape\n",
    "            test_features.append(mfccs.reshape(1, -1))\n",
    "\"\"\"\n",
    "\n",
    "print(\"---Making Predictions---\")\n",
    "            \n",
    "# Convert list of arrays into a single numpy array\n",
    "test_features = np.vstack(test_features)\n",
    "test_scaled = scaler.transform(test_features)\n",
    "test_pca = pca.transform(test_scaled)\n",
    "\n",
    "# Predict using the SVM (with decoded predictions)\n",
    "test_pred = svm_clf.predict(test_pca)\n",
    "test_pred_labels = label_encoder.inverse_transform(test_pred)\n",
    "\n",
    "# Save to a CSV for submission to Kaggle\n",
    "with open(\"svm.csv\", 'w', newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"filename\", \"emotion\"])\n",
    "    for i, emotion in enumerate(test_pred_labels):\n",
    "        writer.writerow([f\"{str(i+1)}.wav\", emotion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80180d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reducing Overfitting through Recursive Feature Extraction(RFE)\n",
    "\n",
    "RFE is a feature selection method that fits a model with the\n",
    "existing features and removes the weakest feature. This fitting process is repeated until a specified\n",
    "number of features remains. In this case, the model is initially fit with all the combined features. RFE ranks the features by their importance to the predictive accuracy. The least important\n",
    "feature is removed recursively. The model is then refitted with the new, reduced set of features. This\n",
    "process is iterated until the specified number of features is reached.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_data(features_path, labels_path):\n",
    "    # Load features and original labels\n",
    "    features = np.load(features_path)\n",
    "    original_labels = np.load(labels_path)\n",
    "    return features, original_labels\n",
    "\n",
    "def train_svm_classifier(features, labels):\n",
    "    scaler = StandardScaler()\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    # Encode labels and scale features\n",
    "    labels_encoded = encoder.fit_transform(labels)\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(features_scaled, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Determine if you should use the dual formulation\n",
    "    use_dual = X_train.shape[0] > X_train.shape[1]  # True if more samples than features\n",
    "\n",
    "    # Initialize the LinearSVC model for RFE\n",
    "    linear_svc = LinearSVC(dual=use_dual, max_iter=20000, tol=1e-4)\n",
    "\n",
    "    # Feature selection with RFE using LinearSVC\n",
    "    rfe = RFE(estimator=linear_svc, n_features_to_select=20, step=1, verbose=3)\n",
    "    rfe.fit(X_train, y_train)\n",
    "\n",
    "    # Transform features using RFE\n",
    "    X_train_rfe = rfe.transform(X_train)\n",
    "    X_val_rfe = rfe.transform(X_val)\n",
    "\n",
    "    # Train the final model using the RBF kernel with selected features\n",
    "    model = SVC(kernel=\"rbf\", C=1, decision_function_shape=\"ovo\", gamma=\"scale\")\n",
    "    model.fit(X_train_rfe, y_train)\n",
    "\n",
    "    # Predict on the validation set with the reduced feature set\n",
    "    y_pred = model.predict(X_val_rfe)\n",
    "    validation_accuracy = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Validation Accuracy: {validation_accuracy}\")\n",
    "\n",
    "    # Save the best model, scaler, encoder, and RFE selector\n",
    "    joblib.dump(model, \"Dataset/svm_model_optimal_rfe.joblib\")\n",
    "    joblib.dump(scaler, \"Dataset/scaler_optimal_rfe.joblib\")\n",
    "    joblib.dump(encoder, \"Dataset/label_encoder_optimal_rfe.joblib\")\n",
    "    joblib.dump(rfe, \"Dataset/rfe_selector_optimal.joblib\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    features, labels = load_data(\"train_features.npy\", \"train_labels.npy\")\n",
    "    train_svm_classifier(features, labels)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Note on Overfitting:\n",
    "Note how we tried to mitigate the overfitting problem explicitly at the end through RFE but also implicitly at several prior points in the data science pipeline. We used PCA to capture 95% variance and thus eliminate highly specfic dimensions in feature space that could potentially cause the model to overfit. We also used K-fold cross validation instead of a simple train test split in order to not make training dependent on just one random split of the available data.\n",
    "\n",
    "Other Ways to Address Overfitting:\n",
    "* Splitting train validation ratio: The dataset this year is pretty large. The typical train validation split is 80% and 20%. You can always experiment with different ratios to find better performance. However, increasing or decreasing one side too much can lead to overfitting too much to the validation data or underfitting to the validation data.\n",
    "* Grid search vs random search:\n",
    "  * Both are ways to tune hyperparameters of your model for better performance. However, both have benefits and downsides.\n",
    "  * Grid search tries all combinations of hyperparameters in the range of values that you provide. Random search randomly samples hyperparameters in the range of values that you provide.\n",
    "  * General fast rule of thumb: Use grid search when there are less hyperparameters that also have more correlation with each other. Use random search when there are too many parameters without correlation with each other to see better trends first.\n",
    "* Early stopping: Use a plot to monitor the validation set performance. When the validation stops improving is when you stop training the model early before it reaches the end of the whole training iterations specified.\n",
    "* Regularization: Introduce a penalty term in the loss function that prevents over-emphasis and weights on a specific parameter. Different regularization methods were covered in class: L1 (Lasso) and L2 (Ridge).\n",
    "* Data augmentation: Create more data that is slightly changed from the given train set if you feel you want more training data.\n",
    "* Too many features: feature selection and dimensionality reduction like PCA.\n",
    "\n",
    "Other general tips:\n",
    "\n",
    "\n",
    "*   Consider using raw audio signals vs extracted features of audio signals vs images to train your models.\n",
    "*   Consider the implications about your data based on the test accuracies of models. For example, if your SVM has a poor accuracy (despite correct implementation), then that most likely implies that your data is probably ont linearly separable. In that case try using kernels or even better for your second model - neural nets!\n",
    "* CNNs (very common for such tasks, although not SOTA) can be used on 1D (WaveNet), 2D (ResNet), or 3D data (many times people assume it's only for 2D images).\n",
    "* Transformers are SOTA but take very long to train, especially with Colab's free GPU, so keep that in mind.\n",
    "* Loading Labels (IMPORTANT): The data for this year has each emotion and their files in a separate folder each without a created train.csv to download. So, please create a train.csv with one column being the filename and second column being the corresponding emotion based on which folder the file is in.\n",
    "  * NOTE: the emotion \"Surprised\" is spelled as \"Suprised\" so use \"Suprised\" across everything\n",
    "* Submission file format: Please be aware of the format and follow the format given on Kaggle of two columns with the same column names and format with the emotions having the first letter capitalized.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
